geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
df %>%
group_by(id, study_type, level) %>%
summarise %>%
gather(key = grouping_var, value = level_type, -id) %>%
ggplot(aes(level_type)) +
geom_bar() +
facet_wrap(~grouping_var, scales = "free")
df_naomit <- df %>% na.omit
model0 <- lmer(relatedness ~ (1|word_pair) + (1|id), data = df_naomit, REML = F)
model1 <- lmer(relatedness ~ study_type + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model1 %>%
tidy() %>%
rename("t-value" = statistic) %>%
select(-group) %>%
kable()
anova(model0, model1)
model2 <- lmer(relatedness ~ level + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model3 <- lmer(relatedness ~ duration + (1|word_pair) + (1|id), data = df_naomit, REML = F)
anova(model0, model2)
anova(model0, model3)
corr <- df %>%
arrange(id) %>%
select(id, relatedness, word_pair) %>%
spread(key = id, value = relatedness) %>%
select(-word_pair) %>%
cor() %>%
as.data.frame() %>%
rownames_to_column("id") %>%
gather(key = participant2, value = correlation, -id) %>%
# Add duration of test, study type and level of participant indicated by id:
left_join(df %>% select(id, study_type, level, duration)) %>%
rename(study_type1 = study_type,
level1 = level) %>%
left_join(by = c("participant2" = "id"), df %>% select(id, study_type, level, duration)) %>%
rename(study_type2 = study_type,
level2 = level) %>%
# Correlations between participant and himself are not interesting,
# so filter them out:
filter(id != participant2)
corr %>%
filter(correlation > .9) %>%
group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
summarise() %>%
kable()
corr %>%
filter(correlation < .5) %>%
group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
summarise() %>%
kable()
df %>%
group_by(word_pair, study_type) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = study_type, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
kable()
df %>%
group_by(word_pair, level) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = level, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
kable()
#Bekijk correlatie/scores tussen groepen alpha, beta en gamma?
#Bekijk correlatie/scores tussen wo, hbo en work?
#Bekijk algemeen wat de gemiddelde scores zijn?
#Gebruik t.test om te kijken of er daadwerkelijk verschil is.
ggplot(df, aes(x = factor(relatedness)) +
geom_density() +
facet_wrap(~study_type)
ggplot(df, aes(x = relatedness)) +
geom_density() +
facet_wrap(~study_type)
df %>%
group_by(word_pair, level) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = level, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
lower.tri() %>%
kable()
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
df <- read_csv("results_csv.csv") %>%
filter(profession != "test") %>%
mutate(start_time = as.POSIXct(as.character(start_time), format = "%Y-%m-%d %H:%M:%S"),
end_time = as.POSIXct(as.character(end_time), format = "%Y-%m-%d %H:%M:%S"),
duration = end_time - start_time) %>%
select(-c(start_time, end_time)) %>%
rownames_to_column("id") %>%
gather(key = word_pair, value = relatedness, -c(id, duration, level, study_type, profession)) %>%
arrange(id)
word_pairs <- read_csv("20190219_wordpairs.csv") %>%
mutate(word_pair = str_replace(wordpairs, " vs. ", "_")) %>%
rename(source = similarity) %>%
select(-wordpairs)
df <- df %>%
full_join(word_pairs)
ci <- function(mean, sd, n){
error <- qnorm(0.975)*sd/sqrt(n)
lower <- mean-error
upper <- mean+error
return(tibble(lower = lower,upper = upper))
}
n <- length(unique(df$id))
description <-
df %>%
group_by(word_pair) %>%
mutate(mean = mean(relatedness),
sd = sd(relatedness),
lower = ci(mean, sd, n)[["lower"]],
upper = ci(mean, sd, n)[["upper"]],
median = median(relatedness)
)
description %>%
group_by(word_pair, mean, sd, lower, upper, median, source) %>%
summarise %>%
arrange(source) %>%
kable()
df %>%
group_by(source) %>%
summarise(mean = mean(relatedness),
sd = sd(relatedness),
lower = ci(mean, sd, n)[["lower"]],
upper = ci(mean, sd, n)[["upper"]],
median = median(relatedness)
) %>%
kable()
ggplot(description, aes(relatedness)) +
geom_density() +
facet_wrap(~ word_pair) +
geom_vline(aes(xintercept = mean), colour = "red", linetype = "dashed") +
geom_vline(aes(xintercept = lower), linetype = "dashed") +
geom_vline(aes(xintercept = upper), linetype = "dashed") +
ggtitle("Density plots of relatedness ratings with mean and 95% confidence interval")
description %>%
group_by(word_pair, sd) %>%
summarise() %>%
filter(sd > 2.5) %>%
arrange(sd) %>%
kable()
ggplot(df, aes(x = relatedness, colour = level)) +
geom_bar() +
facet_wrap(~id)
ggplot(df, aes(x = relatedness)) +
geom_density() +
facet_wrap(~study_type)
ggplot(df, aes(x = relatedness)) +
geom_density() +
facet_wrap(~level)
ggplot(df, aes(duration)) +
geom_density() +
geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
df %>%
group_by(id, study_type, level) %>%
summarise %>%
gather(key = grouping_var, value = level_type, -id) %>%
ggplot(aes(level_type)) +
geom_bar() +
facet_wrap(~grouping_var, scales = "free")
df_naomit <- df %>% na.omit
model0 <- lmer(relatedness ~ (1|word_pair) + (1|id), data = df_naomit, REML = F)
model1 <- lmer(relatedness ~ study_type + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model1 %>%
tidy() %>%
rename("t-value" = statistic) %>%
select(-group) %>%
kable()
anova(model0, model1)
model2 <- lmer(relatedness ~ level + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model3 <- lmer(relatedness ~ duration + (1|word_pair) + (1|id), data = df_naomit, REML = F)
anova(model0, model2)
anova(model0, model3)
corr <- df %>%
arrange(id) %>%
select(id, relatedness, word_pair) %>%
spread(key = id, value = relatedness) %>%
select(-word_pair) %>%
cor() %>%
as.data.frame() %>%
rownames_to_column("id") %>%
gather(key = participant2, value = correlation, -id) %>%
# Add duration of test, study type and level of participant indicated by id:
left_join(df %>% select(id, study_type, level, duration)) %>%
rename(study_type1 = study_type,
level1 = level) %>%
left_join(by = c("participant2" = "id"), df %>% select(id, study_type, level, duration)) %>%
rename(study_type2 = study_type,
level2 = level) %>%
# Correlations between participant and himself are not interesting,
# so filter them out:
filter(id != participant2)
corr %>%
filter(correlation > .9) %>%
group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
summarise() %>%
kable()
corr %>%
filter(correlation < .5) %>%
group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
summarise() %>%
kable()
df %>%
group_by(word_pair, study_type) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = study_type, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
kable()
df %>%
group_by(word_pair, level) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = level, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
kable()
#Bekijk correlatie/scores tussen groepen alpha, beta en gamma?
#Bekijk correlatie/scores tussen wo, hbo en work?
#Bekijk algemeen wat de gemiddelde scores zijn?
#Gebruik t.test om te kijken of er daadwerkelijk verschil is.
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
df <- read_csv("results_csv.csv") %>%
filter(profession != "test") %>%
mutate(start_time = as.POSIXct(as.character(start_time), format = "%Y-%m-%d %H:%M:%S"),
end_time = as.POSIXct(as.character(end_time), format = "%Y-%m-%d %H:%M:%S"),
duration = end_time - start_time) %>%
select(-c(start_time, end_time)) %>%
rownames_to_column("id") %>%
gather(key = word_pair, value = relatedness, -c(id, duration, level, study_type, profession)) %>%
arrange(id)
word_pairs <- read_csv("20190219_wordpairs.csv") %>%
mutate(word_pair = str_replace(wordpairs, " vs. ", "_")) %>%
rename(source = similarity) %>%
select(-wordpairs)
df <- df %>%
full_join(word_pairs)
ci <- function(mean, sd, n){
error <- qnorm(0.975)*sd/sqrt(n)
lower <- mean-error
upper <- mean+error
return(tibble(lower = lower,upper = upper))
}
n <- length(unique(df$id))
description <-
df %>%
group_by(word_pair) %>%
mutate(mean = mean(relatedness),
sd = sd(relatedness),
lower = ci(mean, sd, n)[["lower"]],
upper = ci(mean, sd, n)[["upper"]],
median = median(relatedness)
)
description %>%
group_by(word_pair, mean, sd, lower, upper, median, source) %>%
summarise %>%
arrange(source) %>%
kable()
df %>%
group_by(source) %>%
summarise(mean = mean(relatedness),
sd = sd(relatedness),
lower = ci(mean, sd, n)[["lower"]],
upper = ci(mean, sd, n)[["upper"]],
median = median(relatedness)
) %>%
kable()
ggplot(description, aes(relatedness)) +
geom_density() +
facet_wrap(~ word_pair) +
geom_vline(aes(xintercept = mean), colour = "red", linetype = "dashed") +
geom_vline(aes(xintercept = lower), linetype = "dashed") +
geom_vline(aes(xintercept = upper), linetype = "dashed") +
ggtitle("Density plots of relatedness ratings with mean and 95% confidence interval")
description %>%
group_by(word_pair, sd) %>%
summarise() %>%
filter(sd > 2.5) %>%
arrange(sd) %>%
kable()
ggplot(df, aes(x = relatedness, colour = level)) +
geom_bar() +
facet_wrap(~id)
ggplot(df, aes(x = relatedness)) +
geom_density() +
facet_wrap(~study_type)
ggplot(df, aes(x = relatedness)) +
geom_density() +
facet_wrap(~level)
ggplot(df, aes(duration)) +
geom_density() +
geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
df %>%
group_by(id, study_type, level) %>%
summarise %>%
gather(key = grouping_var, value = level_type, -id) %>%
ggplot(aes(level_type)) +
geom_bar() +
facet_wrap(~grouping_var, scales = "free")
df_naomit <- df %>% na.omit
model0 <- lmer(relatedness ~ (1|word_pair) + (1|id), data = df_naomit, REML = F)
model1 <- lmer(relatedness ~ study_type + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model1 %>%
tidy() %>%
rename("t-value" = statistic) %>%
select(-group) %>%
kable()
anova(model0, model1)
model2 <- lmer(relatedness ~ level + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model3 <- lmer(relatedness ~ duration + (1|word_pair) + (1|id), data = df_naomit, REML = F)
anova(model0, model2)
anova(model0, model3)
corr <- df %>%
arrange(id) %>%
select(id, relatedness, word_pair) %>%
spread(key = id, value = relatedness) %>%
select(-word_pair) %>%
cor() %>%
as.data.frame() %>%
rownames_to_column("id") %>%
gather(key = participant2, value = correlation, -id) %>%
# Add duration of test, study type and level of participant indicated by id:
left_join(df %>% select(id, study_type, level, duration)) %>%
rename(study_type1 = study_type,
level1 = level) %>%
left_join(by = c("participant2" = "id"), df %>% select(id, study_type, level, duration)) %>%
rename(study_type2 = study_type,
level2 = level) %>%
# Correlations between participant and himself are not interesting,
# so filter them out:
filter(id != participant2)
corr %>%
filter(correlation > .9) %>%
group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
summarise() %>%
kable()
corr %>%
filter(correlation < .5) %>%
group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
summarise() %>%
kable()
df %>%
group_by(word_pair, study_type) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = study_type, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
kable()
df %>%
group_by(word_pair, level) %>%
summarise(mean = mean(relatedness)) %>%
spread(key = level, value = mean) %>%
ungroup() %>%
select(-word_pair) %>%
cor() %>%
kable()
#Bekijk correlatie/scores tussen groepen alpha, beta en gamma?
#Bekijk correlatie/scores tussen wo, hbo en work?
#Bekijk algemeen wat de gemiddelde scores zijn?
#Gebruik t.test om te kijken of er daadwerkelijk verschil is.
---
title: "Results WordSim353 Assignment 1"
author: "Fleur Petit(), Jorrit Jorritsma(), Debby Lam (4298772) "
date: "23 February 2019"
output: pdf_document
---
---
title: "Results WordSim353 Assignment 1"
author: "Fleur Petit, Jorrit Jorritsma, Debby Lam (4298772) "
date: "23 February 2019"
output: pdf_document
---
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
unlink('Results_WordSim353_cache', recursive = TRUE)
install.packages("mikTek")
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
ggplot(df, aes(duration)) +
geom_density() +
geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
ggplot(df, aes(duration)) +
geom_density() +
geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
ggplot(df, aes(duration)) +
geom_density() +
geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
ggplot(df, aes(duration)) +
geom_density() +
geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
geom_text(aes(y = .3, label = id)) +
facet_wrap(~level, scales = "free")
similar_words <- score_df[,sim_index]
dissimalar_words <- score_df[,-(sim_index)]
#Calculate the total average mean of every word pair
total_score <- colSums(df[,5:34])/nrow(df)
#Experimentation in Psychology and Linguistics assignment 1 part 2
library(ggplot2)
library(tidyverse)
#Read our results from assignment 1
df <- read.csv("results.csv", header= TRUE)
df <- df[23:60,]
rownames(df) <- NULL
#Count the amount of responses per score
response <- t(df[,5:34]) %>% as.data.frame()
#plot histogram plots for each participant
ggplot(data=response, aes(x=factor(response$V17))) +
geom_bar(stat = "count") + labs(title="histogram of scores for participant 17") + geom_text(stat='count',aes(label=..count..),vjust=-1) +
xlab("Participant 17")
#Create a correlation matrix for every participant
cor_matrix <- round(cor(t(df[,5:34])),3)
cor_matrix <- as.data.frame(cor_matrix)
cor_matrix[upper.tri(cor_matrix)] <- NA
#Calculate the total average mean of every word pair
total_score <- colSums(df[,5:34])/nrow(df)
#Seperate similar and dissimilar word pairs
score_df <- df[,5:34]
sim_index <- c(2,5,6,8,9,10,16,18,19,20,22,23,26,29,30)
similar_words <- score_df[,sim_index]
dissimalar_words <- score_df[,-(sim_index)]
#Seperate similar and dissimilar word pairs
score_df <- df[,5:34]
#Experimentation in Psychology and Linguistics assignment 1 part 2
library(ggplot2)
library(tidyverse)
#Read our results from assignment 1
df <- read.csv("results.csv", header= TRUE)
df <- df[23:60,]
rownames(df) <- NULL
#Experimentation in Psychology and Linguistics assignment 1 part 2
library(ggplot2)
library(tidyverse)
#Read our results from assignment 1
df <- read.csv("results_csv.csv", header= TRUE)
df <- df[23:60,]
rownames(df) <- NULL
#Count the amount of responses per score
response <- t(df[,5:34]) %>% as.data.frame()
#plot histogram plots for each participant
ggplot(data=response, aes(x=factor(response$V17))) +
geom_bar(stat = "count") + labs(title="histogram of scores for participant 17") + geom_text(stat='count',aes(label=..count..),vjust=-1) +
xlab("Participant 17")
#Create a correlation matrix for every participant
cor_matrix <- round(cor(t(df[,5:34])),3)
cor_matrix <- as.data.frame(cor_matrix)
cor_matrix[upper.tri(cor_matrix)] <- NA
#Calculate the total average mean of every word pair
total_score <- colSums(df[,5:34])/nrow(df)
#Seperate similar and dissimilar word pairs
score_df <- df[,5:34]
sim_index <- c(2,5,6,8,9,10,16,18,19,20,22,23,26,29,30)
similar_words <- score_df[,sim_index]
dissimalar_words <- score_df[,-(sim_index)]
#Bekijk correlatie/scores tussen groepen alpha, beta en gamma?
#Bekijk correlatie/scores tussen wo, hbo en work?
#Bekijk algemeen wat de gemiddelde scores zijn?
#Gebruik t.test om te kijken of er daadwerkelijk verschil is.
#Seperate similar and dissimilar word pairs
score_df <- df[,5:34]
sim_index <- c(2,5,6,8,9,10,16,18,19,20,22,23,26,29,30)
similar_words <- score_df[,sim_index]
dissimalar_words <- score_df[,-(sim_index)]
View(dissimalar_words)
#Seperate similar and dissimilar word pairs
score_df <- df[,5:34]
sim_index <- c(2,5,6,8,9,10,16,18,19,20,22,23,26,29,30)
similar_words <- score_df[,sim_index]
dissimalar_words <- score_df[,-(sim_index)]
View(response)
View(score_df)
shiny::runApp('~/UU Master/Year 1/Experimentation in Psychology and Linguistics/Assignment 1/Code + R/assignment1')
