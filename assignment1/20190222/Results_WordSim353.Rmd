---
title: "Word Relatedness Assignment 1"
author: "Fleur Petit(5583837), Jorrit Jorritsma(3845567), Debby Lam (4298772)"
date: "22 February 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('knitr')
library('lme4')
library('broom')
```

## Columns and classes of the data

Column "source" has been added to indicate the source-file of the wordpair. I.e. either the file with dissimilar or with similar words.

```{r}

df <- read_csv("20190222_results_groups.csv") %>%
  filter(profession != "test") %>%
  mutate(start_time = as.POSIXct(as.character(start_time), format = "%Y-%m-%d %H:%M:%S"),
         end_time = as.POSIXct(as.character(end_time), format = "%Y-%m-%d %H:%M:%S"),
         duration = end_time - start_time) %>%
  select(-c(start_time, end_time)) %>%
  rownames_to_column("id") %>%
  gather(key = word_pair, value = relatedness, -c(id, duration, level, study_type, profession)) %>%
  arrange(id)

word_pairs <- read_csv("20190219_wordpairs.csv") %>%
  mutate(word_pair = str_replace(wordpairs, " vs. ", "_")) %>%
  rename(source = similarity) %>%
  select(-wordpairs)

df <- df %>%
  full_join(word_pairs)

``` 



```{r}
## Function to calculate the 95% confidence interval

ci <- function(mean, sd, n){
  error <- qnorm(0.975)*sd/sqrt(n)
  lower <- mean-error
  upper <- mean+error
  return(tibble(lower = lower,upper = upper))
}

```

## Mean, standard deviation, lower and upper 95% confidence interval, median of the word pairs

Participants were asked to rate the relatedness of word pairs. More specifically, we introduced the experiment as follows:

"In this experiment you will have to indicate how closely related pairs of words are. For example `flying` and `airplane` are closely related, while `pear` and `acceptance` are not. At the start of the experiment you will furthermore be asked to indicate your studies of profession."

With each word pair we asked:

"Please rate how closely the words are related. 0 means that they are not related at all. 10 means that they are very closely related."

In the below table one can see the descriptive statistics of relatedness ratings of each word pair.

```{r}

n <- length(unique(df$id))

description <-
  df %>%
  group_by(word_pair) %>%
  mutate(mean = mean(relatedness),
            sd = sd(relatedness),
            lower = ci(mean, sd, n)[["lower"]],
            upper = ci(mean, sd, n)[["upper"]],
            median = median(relatedness)
            )

description %>% 
  group_by(word_pair, mean, sd, lower, upper, median, source) %>% 
  summarise %>%
  arrange(source) %>%
  kable() 
```

The relatedness ratings are very different for word pairs from the "similar" dataset and word pairs from the "dissimilar" dataset (see the table below). This may indicate that word relatedness and word similarity are rated according to similar standards.

```{r}
df %>%
  group_by(source) %>%
  summarise(mean = mean(relatedness),
          sd = sd(relatedness),
          lower = ci(mean, sd, n)[["lower"]],
          upper = ci(mean, sd, n)[["upper"]],
          median = median(relatedness)
          ) %>%
  kable()
  

```



## Density plots of relatedness rateings per word pair with mean and 95% confidence interval

```{r}

ggplot(description, aes(relatedness)) +
  geom_density() +
  facet_wrap(~ word_pair) +
  geom_vline(aes(xintercept = mean), colour = "red", linetype = "dashed") +
  geom_vline(aes(xintercept = lower), linetype = "dashed") +
  geom_vline(aes(xintercept = upper), linetype = "dashed") +
  ggtitle("Density plots of relatedness ratings with mean and 95% confidence interval")
  

```

## Pairs with a relatively large spread

A sd > 2.5 has been chosen arbitrarily to indicate a relatively large spread.

```{r}

description %>%
  group_by(word_pair, sd) %>%
  summarise() %>%
  filter(sd > 2.5) %>%
  arrange(sd) %>%
  kable()

```

## Relatedness rating frequencies per participant

It can be noticed that there are differences in how participants rate the word pairs. Some participants go for extreme ratings more often, while others rate more gradually. The different groups do not seem to give an explanation for this in the graph below.

```{r, fig.height = 10, fig.width = 6}

ggplot(df, aes(x = relatedness, colour = study_type)) +
  geom_bar() +
  facet_grid(id ~ level, scales = "free")

```

## Distributions of participants among different groups

```{r, fig.height = 2}
df %>%
  group_by(id, study_type, level) %>% 
  summarise %>%
  gather(key = grouping_var, value = level_type, -id) %>%
  ggplot(aes(level_type)) +
  geom_bar() +
  facet_wrap(~grouping_var, scales = "free")

```

## Relatedness distribution 

### Per `study_type`

The density distribution is similar for the different groups. This seems to confirm what has been noted earlier: the different groups do not seem to give an explanation for different types of relatedness rating sidtributions.

```{r, fig.height = 2}

ggplot(df, aes(x = relatedness)) +
  geom_density() +
  facet_wrap(~study_type)

```

### Per `level`

The WO participants have given slightly more extreme rating than HBO participants.

```{r, fig.height = 2}

ggplot(df, aes(x = relatedness)) +
  geom_density() +
  facet_wrap(~level)

```

## Duration denisty

Participant 7 took very long to complete the questionnaire in comparison with the others.

```{r, fig.height = 2}

ggplot(df, aes(duration)) +
  geom_density() +
  geom_vline(aes(xintercept = duration, colour = study_type), linetype = "dashed") +
  geom_text(aes(y = .3, label = id)) +
  facet_wrap(~level, scales = "free")

```

## Correlations

### Between participants

```{r}

corr <- df %>%
  arrange(id) %>%
  select(id, relatedness, word_pair) %>%
  spread(key = id, value = relatedness) %>%
  select(-word_pair) %>%
  cor()

corr[lower.tri(corr)] <- NA

corr <- corr %>%
  as.data.frame() %>%
  rownames_to_column("id") %>%
  gather(key = participant2, value = correlation, -id) %>%
  # Correlations between participant and himself are not interesting,
  # so filter them out:
  filter(id != participant2 & !is.na(correlation)) %>%
  # Add duration of test, study type and level of participant indicated by id:
  left_join(df %>% select(id, study_type, level, duration)) %>%
  rename(study_type1 = study_type,
         level1 = level) %>%
  left_join(by = c("participant2" = "id"), df %>% select(id, study_type, level, duration)) %>%
  rename(study_type2 = study_type,
         level2 = level)  %>%
  group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
  summarise()

```

In the table below we can see that high correlations, above .9, occur between participants of different groups, and not only between participants of the same group.

```{r}

corr %>%
  filter(correlation > .9) %>%
  group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
  summarise() %>%
  kable()
```

Low correlations, of lower than .5 occur only between one specific one specific participant, participant 7, and two others. Participant 7 is one of the two participants with a gamma and hbo education. Additionally, we have seen earlier that participant 7 took relatively long to complete the form.

```{r}
corr %>%
  filter(correlation < .5) %>%
  group_by(id, participant2, correlation, study_type1, level1, study_type2, level2) %>%
  summarise() %>%
  kable()

df %>%
  filter(study_type == "gamma" & level == "hbo") %>%
  group_by(id, level, study_type, profession, duration) %>%
  summarise() %>%
  kable()

```


## Does a model that includes `study_type` explain the variance better than one that does not?

We will use an `lmer` model from the `lme4` package, because we we are interested in the effects of `study_type`, and not the individual differences that we can not control for. The intercept of each individual (`id`) will be defined as a random effect. We will leave out the `NA`'s.

Furthermore, `word_pair` will be defined as a random effect. At this moment we are mainly interested in whether `study_type` explains differences in relatedness in general. We don't want to look at the effect of `study_type` on the relatedness ratings of each `word_pair`.

### The null-model

The null-model only includes the intercept for each `word_pair` and the intercept of each individual as a random effects.

```{r, echo = T}

df_naomit <- df %>% na.omit

model0 <- lmer(relatedness ~ (1|word_pair) + (1|id), data = df_naomit, REML = F)

```

### The alternative model (includes `study_type`)

In the table we can see that there is a relatively large difference between the ratings of people with a `gamma` background and those with an `alpha background`. `estimate` > `(Intercept)` gives us the relatedness intercept of relatedness of `people` with an `alpha` background. The `estimate` value at `study_typebeta` gives the difference with this intercept. The same holds for `study_typegamma`.

```{r, echo = T}

model1 <- lmer(relatedness ~ study_type + (1|word_pair) + (1|id), data = df_naomit, REML = F)

model1 %>%
  tidy() %>%
  rename("t-value" = statistic) %>%
  select(-group) %>%
  kable()

```

### Does the alternate model explain significantly more of the variance?

The p-value indicates that a model that includes `study_type` does not explain significantly more of the variance.

```{r, echo = T}

anova(model0, model1)

```

## How about `level` and `duration` and combinations of those and `study_type`?

```{r, echo = T}

model2 <- lmer(relatedness ~ level + (1|word_pair) + (1|id), data = df_naomit, REML = F)
model3 <- lmer(relatedness ~ duration + (1|word_pair) + (1|id), data = df_naomit, REML = F)
```

`level`

```{r}
anova(model0, model2)
```

`duration`

```{r}

anova(model0, model3)

```

Models including `level` xor `duration` do not explain significantly more of the variance than the null-model.

