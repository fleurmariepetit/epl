data <- Boston
kcv(formula, Boston, 12)
}
kcv <- function(formula, data, k) {
outcome <- as.character(formula(mod))[2]
cuts <- cut(data[[outcome]], k)
data <- data %>% mutate(cuts = cuts)
mses <- array()
for (i in 1:k) {
train <- data %>% filter(cuts %in% levels(cuts)[-i])
validate <- data %>% filter(cuts %in% levels(cuts)[i])
model <- lm(formula, data = train)
mse <- mean((validate[[outcome]] - predict(model, newdata = validate))^2, na.rm = T)
mses[i] <- mse
}
return(mean(mses))
}
model_list <- c("lin_mod", "pn3_mod", "ns3_mod")
for (mod in model_list) {
mod <- eval(parse(text = mod))
formula <- formula(mod)
data <- Boston
kcv(formula, Boston, 12)
}
kcv <- function(formula, data, k) {
outcome <- as.character(formula(mod))[2]
cuts <- cut(data[[outcome]], k)
data <- data %>% mutate(cuts = cuts)
mses <- array()
for (i in 1:k) {
train <- data %>% filter(cuts %in% levels(cuts)[-i])
validate <- data %>% filter(cuts %in% levels(cuts)[i])
model <- lm(formula, data = train)
mse <- mean((validate[[outcome]] - predict(model, newdata = validate))^2, na.rm = T)
mses[i] <- mse
}
return(mean(mses))
}
model_list <- c("lin_mod", "pn3_mod", "ns3_mod")
for (mod in model_list) {
mod <- eval(parse(text = mod))
formula <- formula(mod)
data <- Boston
print(kcv(formula, Boston, 12))
}
model_list <- c("lin_mod", "pn3_mod", "pc3_mod", "bs1_mod", "ns3_mod")
for (mod in model_list) {
mod <- eval(parse(text = mod))
formula <- formula(mod)
data <- Boston
print(kcv(formula, Boston, 12))
}
kcv <- function(formula, data, k) {
outcome <- as.character(formula(mod))[2]
cuts <- cut(data[[outcome]], k)
data <- data %>% mutate(cuts = cuts)
mses <- array()
for (i in 1:k) {
train <- data %>% filter(cuts %in% levels(cuts)[-i])
validate <- data %>% filter(cuts %in% levels(cuts)[i])
model <- lm(formula, data = train)
mse <- mean((validate[[outcome]] - predict(model, newdata = validate))^2, na.rm = T)
mses[i] <- mse
}
return(mean(mses))
}
brks <- c(-Inf, 7, 15, 22, Inf)
pw5_mod <- lm(medv ~ I(cut(lstat, brks)), Boston)
model_list <- c("lin_mod", "pn3_mod", "pc3_mod", "pw5_mod", "bs1_mod", "ns3_mod")
for (mod in model_list) {
mod <- eval(parse(text = mod))
formula <- formula(mod)
data <- Boston
print(kcv(formula, Boston, 12))
}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
library(ISLR)
library(tidyverse)
ggplot(Default, aes(balance, income, colour = default)) +
geom_point()
ggplot(Default, aes(balance, income, colour = default)) +
geom_point(shape = 1)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = 0.2)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = 0.2, fill = NULL)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = 0.2, fill = 0)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = 0.2, colour = NULL)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = 0.2, fill = F)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = 0)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = .01)
ggplot(Default, aes(balance, income, colour = default)) +
geom_count(alpha = .2)
ggplot(Default, aes(balance, income, colour = default)) +
geom_point(shape = 2)
ggplot(Default, aes(balance, income, colour = default)) +
geom_point(shape = 1)
ggplot(Default, aes(balance, income, colour = default)) +
geom_point(shape = 1)
p <- ggplot(Default, aes(balance, income, colour = default)) +
geom_point(shape = 1)
p + facet_grid(cols = vars(student))
p + facet_grid(cols = vars(student))
p <- ggplot(Default, aes(balance, income, colour = default)) +
geom_point(shape = 1)
p
Default %>%
mutate(student = ifelse("yes", 1, 0))
Default <-
Default %>%
mutate(student = ifelse("yes", 1, 0))
ncols(Default)
default_train <- sample(Default, .8*nrow(Default))
default_train <- sample(Default, .8*nrow(Default), raplace = T)
default_train <- sample(Default, .8*nrow(Default), replace = T)
nrow(default_train)
nrow(Default)
default_train <- sample(x = Default, size = .8*nrow(Default), replace = T)
length(default_train)
View(Default)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
library(ISLR)
library(tidyverse)
View(Default)
Default
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
library(ISLR)
library(tidyverse)
unique(Default$student)
Default <-
Default %>%
mutate(student = ifelse("Yes", 1, 0))
View(Default)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(class)
library(ISLR)
library(tidyverse)
Default <-
Default %>%
mutate(student = ifelse(student == "Yes", 1, 0))
View(Default)
default_test <- setdiff(Default, default_train)
default_train <- sample(x = Default, size = .8*nrow(Default), replace = T)
default_test <- setdiff(Default, default_train)
default_test <- setdiff(default_train, Default)
default_train
?sample
default_train <- sample_n(tbl = Default, size = .8*nrow(Default))
default_test <- setdiff(default_train, Default)
default_test
default_train
default_test <- setdiff(Default, default_train)
default_test
set.seed(30)
Default <-
Default %>%
mutate(student = ifelse(student == "Yes", 1, 0))
default_train <- sample_n(tbl = Default, size = .8*nrow(Default))
default_test <- setdiff(Default, default_train)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(ISLR)
library(tidyverse)
library(pROC)
library(rpart)
library(rpart.plot)
library(randomForest)
forest_mod
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(ISLR)
library(tidyverse)
library(pROC)
library(rpart)
library(rpart.plot)
library(randomForest)
cardiovascular_treatment <- read_csv("data/cardiovascular_treatment.csv")
lr_mod <- glm(response ~ ., family = binomial(), cardiovascular_treatment)
lr_matrix <- table(true = cardiovascular_treatment$response, predicted = ifelse(predict(lr_mod, type = "response") <= .5, 0, 1))
test_metrics <- function(true, predicted) {
matrix <- table(true = true, predicted = predicted)
tn <- matrix[1, 1]
tp <- matrix[2, 2]
fn <- matrix[2, 1]
fp <- matrix[1, 2]
p <- tp + fn
n <- tn + fp
acc <- (tn + tp) / (n + p)
tnr <- tn / n
fpr <- 1 - tnr
ppv <- tp / (tp + fp)
npv <- tn / (tn + fn)
metrics <- tibble(tn, tp, fn, fp, acc, tnr, fpr, ppv, npv)
return(metrics)
}
test_metrics(true = cardiovascular_treatment$response, predicted = ifelse(predict(lr_mod, type = "response") <= .5, 0, 1))
lda_mod <- lda(response ~ ., data = cardiovascular_treatment)
test_metrics(true = cardiovascular_treatment$response, predicted = predict(lda_mod)$class)
new_patients <- read_csv("data/new_patients.csv")
lr_metrics <- test_metrics(true = new_patients$response, predicted = ifelse(predict(lr_mod, type = "response", newdata =  new_patients) <= .5, 0, 1)) %>%
mutate(name = "lr_metrics")
lda_metrics <- test_metrics(true = new_patients$response, predicted = predict(lda_mod, newdata = new_patients)$class) %>%
mutate(name = "lda_metrics")
lr_metrics %>%
bind_rows(lda_metrics)
# Brier score
bs <- function(predicted, true) {
mean((predicted - true)^2)
}
bs(predicted = predict(lr_mod, type = "response", newdata = new_patients), true = new_patients$response)
bs(predicted = predict(lda_mod, newdata = new_patients)$posterior[,2], true = new_patients$response)
lr1_mod <- glm(response ~ severity + age + bb_score, data = cardiovascular_treatment)
lr2_mod <- glm(response ~ age + I(age^2) + gender + bb_score * prior_cvd * dose, data = cardiovascular_treatment)
roc_lr1 <- roc(response = cardiovascular_treatment$response, predictor = predict(lr1_mod, type = "response"))
roc_lr2 <- roc(response = cardiovascular_treatment$response, predictor = predict(lr2_mod, type = "response"))
ggroc(roc_lr1)
ggroc(roc_lr2)
roc_lr1
roc_lr2
# fit lda model, i.e. calculate model parameters
lda_iris <- lda(Species ~ ., data = iris)
# use those parameters to compute the first linear discriminant
first_ld <- -c(as.matrix(iris[, -5]) %*% lda_iris$scaling[,1])
# plot
tibble(
ld = first_ld,
Species = iris$Species
) %>%
ggplot(aes(x = ld, fill = Species)) +
geom_histogram(binwidth = .5, position = "identity", alpha = .9) +
scale_fill_viridis_d(guide = ) +
theme_minimal() +
labs(
x = "Discriminant function",
y = "Frequency",
main = "Fisher's linear discriminant function on Iris species"
) +
theme(legend.position = "top")
colnames(iris)
nrow(iris)
iris %>%
group_by(Species) %>%
summarise(mean(Sepal.Length), mean(Sepal.Width), mean(Petal.Length), mean(Petal.Width))
iris %>%
gather(key = feature, value = value, -Species) %>%
ggplot(aes(value, colour = feature)) +
geom_density(aes(fill = feature), alpha = 0.2) +
facet_wrap(~Species, scales = "free")
lda_iris_sepal <- lda(Species ~ Sepal.Length + Sepal.Width, data = iris)
table(predicted = predict(lda_iris)$class, true = iris$Species)
table(predicted = predict(lda_iris_sepal)$class, true = iris$Species)
iris_tree_mod <- rpart(formula = Species ~ ., data = iris)
rpart.plot(iris_tree_mod)
ggplot(data = iris, aes(Petal.Length, Petal.Width)) +
geom_segment(aes(x = 2.5, y = 0, xend = 2.5, yend = 2.5)) +
geom_segment(aes(x = 0, y = 1.8, xend = 7, yend = 1.8)) +
geom_point(aes(colour = Species))
iris_tree_full_mod <- rpart(formula = Species ~ ., data = iris, control = rpart.control(minsplit = 2))
rpart.plot(iris_tree_full_mod)
(forest_mod <- randomForest(Species ~ ., data = iris))
data.frame(importance(forest_mod)) %>%
rownames_to_column(var = "Variables") %>%
ggplot(aes(x = Variables, y = MeanDecreaseGini)) +
geom_col()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DAAG)
head(anscombe)
head(anscombe)
colMeans(anscombe)
ancombe %>% var %>% diag
anscombe %>% var %>% diag
anscombe
fit <- amscombe %>%
lm(y1 ~x1)
fit <- anscombe %>%
lm(y1 ~x1)
fit <- anscombe %>%
lm(y1 ~ x1, .)
summary(fit)
y_hat <- fit %>%
fitted.values()
y_hat
predict.lm(fit, newdata = new.x1)
new.x1 <- data.frame(x1 = 1:20)
predict.lm(fit, newdata = new.x1)
prediction(fit, interval = "prediction")
prediction(fit, interval = prediction)
predict(fit, interval = "prediction")
DAAG::CVlm(anscombe, fit, prinit = F)
DAAG::CVlm(anscombe, fit, printit = F)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(tidyverse)
library(ca)
load(file = "data/questionnaire.csv")
getwd()
load(file = "Google Drive/UU/Masters/Year_1/Quartile_2/Data_Analysis_and_Visualisation/Practica/11_Unsupervised_learning_PCA_CA/data/questionnaire.csv")
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
install.packages("ggdendro", "dendextend")
install.packages(c("ggdendro", "dendextend"))
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
install.packages("igraph")
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(ggdendro)
library(dendextend)
library(ISLR)
library(tidyverse)
read_csv("data/clusterdata.csv")
knitr::opts_chunk$set(echo = TRUE)
library(igraph)
library(ggdendro)
library(dendextend)
library(ISLR)
library(tidyverse)
df <- read_csv("data/clusterdata.csv")
ggplot(df, aes(x1, x2)) +
geom_point() +
coord_fixed()
k3 <- kmeans(df, centers = 3)
k5 <- kmeans(df, centers = 5)
df %>%
mutate(k3 = k3$cluster,
k5 = k5$cluster) %>%
gather(key = k, value = cluster, c(k3, k5)) %>%
ggplot(aes(x1, x2, colour = cluster)) +
geom_point() +
facet_wrap(~k) +
coord_fixed()
df %>%
mutate(k3 = factor(k3$cluster),
k5 = factor(k5$cluster)) %>%
gather(key = k, value = cluster, c(k3, k5)) %>%
ggplot(aes(x1, x2, colour = cluster)) +
geom_point() +
facet_wrap(~k) +
coord_fixed()
cl <- hclust(dist(df), method = "complete")
al <- hclust(dist(df), method = "average")
ggdendrogram(data = cl)
ggdendrogram(data = al)
dendlist(cl, al)
?dendlist
dendlist(c(cl, al))
dendlist(cl, al)
dendlist(cl)
View(al)
dendlist(hclust(dist(df), method = "complete"))
cl <- hclust(dist(df), method = "complete") %>% a.dendogram
cl <- hclust(dist(df), method = "complete") %>% as.dendogram
cl <- hclust(dist(df), method = "complete") %>% as.dendrogram
al <- hclust(dist(df), method = "average") %>% as.dendrogram
ggdendrogram(data = cl)
ggdendrogram(data = al)
dendlist(cl)
dendlist(cl, al)
dendlist(cl, al) %>%
tanglegram()
cutree(tree = cl, k = 3)
df %>%
mutate(k3 = factor(k3$cluster),
hccut = cutree(tree = cl, k = 3)
) %>%
gather(key = model, value = cluster, c(k3, hccut)) %>%
ggplot(aes(x1, x2, colour = cluster)) +
geom_point() +
facet_wrap(~model) +
coord_fixed()
`12_dist` <- function(x, y) {
sqrt(sum((x-y)^2))
}
`12_dist`(x,y)
`12_dist` <- function(x, y) {
sqrt(sum((x-y)^2))
}
x <- c(1:10)
y <- c(5:15)
`12_dist`(x,y)
`12_dist` <- function(x, y) {
sqrt(sum((x-y)^2))
}
x <- c(1:10)
y <- c(5:14)
`12_dist`(x, y)
?sample
observations <- df
clusters <- observations %>%
mutate(cluster1 = sample(1:k, size = nrow(observations)))
k = 10
k <- 2
clusters <- observations %>%
mutate(cluster1 = sample(1:k, size = nrow(observations)))
clusters <- observations %>%
mutate(cluster1 = sample(1:k, size = nrow(observations, replace = T)))
clusters <- observations %>%
mutate(cluster1 = sample(1:k, size = nrow(observations), replace = T))
View(clusters)
clusters %>%
group_by(cluster1) %>%
summarise_each(funs(mean), -cluster1)
View(clusters)
clusters %>%
group_by(cluster1)
clusters %>%
group_by(cluster1) %>%
summarise_each(funs(mean), -cluster1)
clusters %>%
group_by(cluster1) %>%
summarise_each(funs(mean), vars(-cluster1))
clusters %>%
group_by(cluster1) %>%
summarise_each(funs(mean), vars(c(1:ncol-1)))
clusters %>%
group_by(cluster1) %>%
summarise_each(funs(mean), vars(1:ncol-1))
clusters %>%
group_by(cluster1) %>%
summarise_at(funs(mean), vars(1:ncol-1))
clusters %>%
group_by(cluster1) %>%
summarise_all(funs(mean))
clusters %>%
group_by(cluster1) %>%
summarise(mean)
clusters %>%
group_by(cluster1) %>%
summarise_all(funs(mean))
View(clusters)
clusters %>%
group_by(cluster1) %>%
mutate_all(funs(mean))
View(clusters)
clusters %>%
group_by(cluster1) %>%
mutate_all(mean = funs(mean))
clusters %>%
group_by(cluster1) %>%
mutate_all(funs(mean))
clusters %>%
group_by(cluster1) %>%
mutate_all(funs(mean = mean))
install.packages('rsconnect')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='epl-assignment', token='AC61DDFF1404E90007FAB946A1429130', secret='b+EbMQobBPHs5juc5YahqWapsMSslYC7Ja0iWZUj')
library(rsconnect)
rsconnect::deployApp('C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353')
shiny::runApp('C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353')
runApp('C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353')
runApp('C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353')
runApp('C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353')
runApp('C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353')
library("rsconnect")
deployApp()
setwd("C:/Users/Fleur/Google Drive/UU/Masters/Year_1/Quartile_3/Experimentation_in_Psychology_and_Linguistics/Assignments/Asssignment1/WordSim353")
deployApp()
rsconnect::setAccountInfo(name='epl-assignment',
token='AC61DDFF1404E90007FAB946A1429130',
secret='b+EbMQobBPHs5juc5YahqWapsMSslYC7Ja0iWZUj')
deployApp()
runApp()
files <- list.files(file.path("./results"), full.names = TRUE)
data <- do.call(rbind, lapply(files, read.csv)) %>%
drop_na()
View(data)
runApp()
View(data)
t(data)
files <- list.files(file.path("./results"), full.names = TRUE)
data <- do.call(rbind, lapply(files, read.csv)) %>%
drop_na()
as_tibble(data)
t(data)
tibble(t(data))
tas_ibble(t(data))
as_tibble(t(data))
as_tibble(t(data),rownames = colnames(data))
as_tibble(t(data),rownames = colnames(data))
as.data.frame(t(data),rownames = colnames(data))
as.data.frame(t(data),rownames = colnames(data)) %>% rownames_to_column()
loadData <- function() {
files <- list.files(file.path("./results"), full.names = TRUE)
data <- do.call(rbind, lapply(files, read.csv)) %>%
drop_na()
as_tibble(data)
}
output$graphs <- renderPlot({
loadData() %>%
gather(key = word_pair, value = similarity) %>%
ggplot(aes(similarity)) +
geom_bar() +
facet_wrap(~word_pair)
})
loadData() %>%
gather(key = word_pair, value = similarity) %>%
ggplot(aes(similarity)) +
geom_bar() +
facet_wrap(~word_pair)
